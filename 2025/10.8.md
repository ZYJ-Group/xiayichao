1.b站学习深度学习的相关视频

（1）了解卷积、池化、搭建神经网络、优化器、反向传播等;

（2）完整的模型训练流程;

（3）怎么利用GPU训练;


2.阅读论文“Attentive Contextual Attention for Cloud Removal”

（1）背景 

•	问题:云层覆盖严重影响遥感图像的质量和可用性，妨碍了对地球的准确观察。大约67%的遥感数据被云层遮挡。

•	传统方法: 基于空间、光谱、时间的技术。但这些方法在面对复杂的云层时往往效果不佳，并且需要大量额外的数据或计算资源。

•	本文方法：AC-Attention是基于CNN 特征，后嵌到一个卷积残差网络（DSen2-CR）框架里使用的。



（2）方法

a.传统注意力机制

b.本文AC注意力机制

原理：在传统注意力机制中添加——权重模块和偏置模块。这些模块分别负责学习权重 W 和偏置 B，并使用它们在一个线性变换函数中调整相似矩阵。

<img width="849" height="463" alt="image" src="https://github.com/user-attachments/assets/d2f1401a-4ce7-419b-80ed-e7c7e3c7617e" />


<img width="367" height="46" alt="image" src="https://github.com/user-attachments/assets/41135226-7ea0-4e6d-997f-54d4ac0c9917" />


<img width="397" height="56" alt="image" src="https://github.com/user-attachments/assets/6c8e8f43-2293-4fd4-ae6c-1c66ac10a541" />

<img width="329" height="52" alt="image" src="https://github.com/user-attachments/assets/67865db6-6bd2-421c-87a9-a4f2f5da798f" />


              H×W×C 就是高×宽×通道数的张量维度记法

              

（3）网络框架ACA-CRNet 

    组成：ACA-CRNet 由 18 层组成，包括 2 层卷积层、14 个 RB 模块和 2 个 RACAB 模块。
    
<img width="1129" height="404" alt="image" src="https://github.com/user-attachments/assets/f2d5190d-1651-4e9c-8c1c-ae0cd49b1917" />

  改动：在现有的DSen2-CR 框架中通过替换两个残差模块（RB），引入了新型的残差 AC 注意力模块（RACAB）。
  
  残差块RB：就是两层 3×3 卷积 + ReLU，把主分支输出按比例系数 α（默认 0.1）缩放后与输入 残差相加。
  
 •	作用：缓解深层网络训练中的退化/梯度消失，让网络更稳定、更容易优化；


 （4）实验
 
   <img width="529" height="454" alt="image" src="https://github.com/user-attachments/assets/1fd300bd-c158-4e2e-badb-8123bef712cf" />

   较低的MAE和SAM值表示更好的重建，而较高的PSNR和SSIM值则反映出更优越的重建性能。
   
   平均绝对误差（MAE）、峰值信噪比（PSNR）、结构相似性指数（SSIM）、光谱角映射（SAM）

   <img width="1075" height="578" alt="image" src="https://github.com/user-attachments/assets/00fe722e-578c-4483-a927-cdbd66d0f0fd" />



  （5）结论与未来
  
  结论：AC-Attention 机制通过动态选择相关特征并排除无关特征，有效提升了云去除的性能。
  
  未来工作： 创建更高效的注意力策略，在捕捉全局特征的同时降低计算成本，以应对高分辨率图像和资源受限环境中注意力机制的平方复杂度。
